"""
PHi-4 ì±—ë´‡ ëª¨ë“ˆ
í•œêµ­ì–´ ì¶”ë¡  AI ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì±„íŒ… APIë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì„ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import os
import torch
from pathlib import Path
from fastapi import APIRouter
from fastapi.responses import JSONResponse

# ì›¹ ê²€ìƒ‰ ë° ìœ„ì¹˜ ê°ì§€ ëª¨ë“ˆ import
from src.web_search import search_web
from src.location import get_location_from_ip_sync, get_location_from_ip_async, needs_location_context

# ë‚ ì”¨ APIìš© import
import httpx
from datetime import datetime, timedelta

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ëª¨ë¸ ê²½ë¡œ ë¡œë“œ
_base_dir = Path(__file__).parent.parent
_models_dir = _base_dir / "models"

def _resolve_model_path(model_name: str, default: str) -> Path:
    """ëª¨ë¸ ê²½ë¡œ í•´ì„: íŒŒì¼ëª…ë§Œ ìˆìœ¼ë©´ models/ í´ë”ì—ì„œ ì°¾ìŒ"""
    path = Path(model_name) if model_name else Path(default)
    if path.is_absolute():
        return path
    if path.parent == Path("."):
        return _models_dir / path
    return _base_dir / path

PHI4_ADAPTER_PATH = _resolve_model_path(
    os.getenv("PHI4_ADAPTER_PATH", ""), "phi-4-reasoning"
)

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì„ ì–¸
chatbot_model = None
chatbot_tokenizer = None
chatbot_loaded = False

# ë¼ìš°í„° ìƒì„±
router = APIRouter(prefix="/api", tags=["chatbot"])

# ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ í‚¤ì›Œë“œ ëª©ë¡
SEARCH_KEYWORDS = [
    "ë‰´ìŠ¤", "ìµœì‹ ", "ì£¼ê°€", "í™˜ìœ¨",
    "ê²€ìƒ‰", "ì°¾ì•„", "ì•Œë ¤ì¤˜", "ëª‡ì‹œ", "ëˆ„ê°€", "ì–¸ì œ",
    "ì‹¤ì‹œê°„", "ì†ë³´", "ê²½ê¸°", "ê²°ê³¼", "ìŠ¤ì½”ì–´", "ìˆœìœ„"
]

# ë‚ ì”¨ APIê°€ í•„ìš”í•œ í‚¤ì›Œë“œ ëª©ë¡
WEATHER_KEYWORDS = ["ë‚ ì”¨", "ê¸°ì˜¨", "ì˜¨ë„", "ìŠµë„", "ë¹„", "ëˆˆ", "ë§‘ìŒ", "íë¦¼", "ëª‡ë„"]


def needs_weather_api(query: str) -> bool:
    """ì§ˆë¬¸ì´ ë‚ ì”¨ APIë¥¼ í•„ìš”ë¡œ í•˜ëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
    return any(keyword in query for keyword in WEATHER_KEYWORDS)


def needs_web_search(query: str) -> bool:
    """ì§ˆë¬¸ì´ ì›¹ ê²€ìƒ‰ì„ í•„ìš”ë¡œ í•˜ëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
    # ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ì€ ì›¹ ê²€ìƒ‰ ëŒ€ì‹  ë‚ ì”¨ API ì‚¬ìš©
    if needs_weather_api(query):
        return False
    return any(keyword in query for keyword in SEARCH_KEYWORDS)


# ê¸°ìƒì²­ API í‚¤
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY")

# í•˜ëŠ˜ ìƒíƒœ ì½”ë“œ
SKY_STATUS = {
    "1": "ë§‘ìŒ", "3": "êµ¬ë¦„ë§ìŒ", "4": "íë¦¼"
}

# ê°•ìˆ˜ í˜•íƒœ ì½”ë“œ
PTY_STATUS = {
    "0": "ì—†ìŒ", "1": "ë¹„", "2": "ë¹„/ëˆˆ", "3": "ëˆˆ", 
    "4": "ì†Œë‚˜ê¸°", "5": "ë¹—ë°©ìš¸", "6": "ë¹—ë°©ìš¸ëˆˆë‚ ë¦¼", "7": "ëˆˆë‚ ë¦¼"
}


def _latlon_to_grid(lat: float, lon: float) -> dict:
    """ìœ„ë„/ê²½ë„ë¥¼ ê¸°ìƒì²­ ê²©ì ì¢Œí‘œë¡œ ë³€í™˜"""
    import math
    
    RE = 6371.00877
    GRID = 5.0
    SLAT1 = 30.0
    SLAT2 = 60.0
    OLON = 126.0
    OLAT = 38.0
    XO = 43
    YO = 136
    
    DEGRAD = math.pi / 180.0
    
    re = RE / GRID
    slat1 = SLAT1 * DEGRAD
    slat2 = SLAT2 * DEGRAD
    olon = OLON * DEGRAD
    olat = OLAT * DEGRAD
    
    sn = math.tan(math.pi * 0.25 + slat2 * 0.5) / math.tan(math.pi * 0.25 + slat1 * 0.5)
    sn = math.log(math.cos(slat1) / math.cos(slat2)) / math.log(sn)
    sf = math.tan(math.pi * 0.25 + slat1 * 0.5)
    sf = math.pow(sf, sn) * math.cos(slat1) / sn
    ro = math.tan(math.pi * 0.25 + olat * 0.5)
    ro = re * sf / math.pow(ro, sn)
    
    ra = math.tan(math.pi * 0.25 + lat * DEGRAD * 0.5)
    ra = re * sf / math.pow(ra, sn)
    theta = lon * DEGRAD - olon
    if theta > math.pi:
        theta -= 2.0 * math.pi
    if theta < -math.pi:
        theta += 2.0 * math.pi
    theta *= sn
    
    nx = int(ra * math.sin(theta) + XO + 0.5)
    ny = int(ro - ra * math.cos(theta) + YO + 0.5)
    
    return {"nx": nx, "ny": ny}


async def get_weather_info(client_ip: str = None) -> str:
    """ê¸°ìƒì²­ APIë¥¼ í†µí•´ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # IP ê¸°ë°˜ ìœ„ì¹˜ ì¡°íšŒ
        location_info = await get_location_from_ip_async(client_ip)
        location = location_info["city"]
        
        # ìœ„ê²½ë„ â†’ ê²©ì ì¢Œí‘œ ë³€í™˜
        grid = _latlon_to_grid(location_info["lat"], location_info["lon"])
        
        # ê¸°ìƒì²­ API ì‹œê°„ ê³„ì‚°
        now = datetime.now()
        base_time = now.strftime("%H") + "00"
        base_date = now.strftime("%Y%m%d")
        
        if now.minute < 40:
            prev_hour = now.hour - 1
            if prev_hour < 0:
                prev_hour = 23
                base_date = (now - timedelta(days=1)).strftime("%Y%m%d")
            base_time = f"{prev_hour:02d}00"
        
        url = "http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getUltraSrtNcst"
        params = {
            "serviceKey": WEATHER_API_KEY,
            "numOfRows": "10",
            "pageNo": "1",
            "dataType": "JSON",
            "base_date": base_date,
            "base_time": base_time,
            "nx": grid["nx"],
            "ny": grid["ny"],
        }
        
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(url, params=params)
            data = response.json()
        
        weather_data = {
            "temperature": None,
            "pty": "0",
            "wind_speed": None,
            "humidity": None,
        }
        
        if "response" in data and "body" in data["response"]:
            items = data["response"]["body"].get("items", {}).get("item", [])
            for item in items:
                category = item.get("category")
                value = item.get("obsrValue")
                
                if category == "T1H":
                    weather_data["temperature"] = float(value)
                elif category == "PTY":
                    weather_data["pty"] = str(int(float(value)))
                elif category == "WSD":
                    weather_data["wind_speed"] = float(value)
                elif category == "REH":
                    weather_data["humidity"] = float(value)
        
        # ë‚ ì”¨ ìƒíƒœ ê²°ì •
        pty = weather_data["pty"]
        if pty != "0" and pty in PTY_STATUS:
            sky_name = PTY_STATUS[pty]
        else:
            sky_name = "ë§‘ìŒ"
        
        # ê²°ê³¼ ë¬¸ìì—´ ìƒì„±
        temp = weather_data["temperature"] if weather_data["temperature"] else "ì¸¡ì • ë¶ˆê°€"
        humidity = weather_data["humidity"] if weather_data["humidity"] else "ì¸¡ì • ë¶ˆê°€"
        wind = weather_data["wind_speed"] if weather_data["wind_speed"] else "ì¸¡ì • ë¶ˆê°€"
        
        result = (
            f"[{location} í˜„ì¬ ë‚ ì”¨]\n"
            f"- ê¸°ì˜¨: {temp}Â°C\n"
            f"- ë‚ ì”¨: {sky_name}\n"
            f"- ìŠµë„: {humidity}%\n"
            f"- í’ì†: {wind}m/s\n"
            f"- ì¸¡ì • ì‹œê°„: {now.strftime('%Y-%m-%d %H:%M')}"
        )
        
        return result
        
    except Exception as e:
        print(f"âš ï¸ ë‚ ì”¨ API ì˜¤ë¥˜: {e}")
        return f"ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


async def load_chatbot_model():
    """PHi-4 ëª¨ë¸ ë¡œë“œ (ì„œë²„ ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
    global chatbot_model, chatbot_tokenizer, chatbot_loaded
    
    if chatbot_loaded:
        return
    
    # ëª¨ë¸ ê²½ë¡œ í™•ì¸
    if not PHI4_ADAPTER_PATH.exists():
        print(f"âš ï¸ PHi-4 ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {PHI4_ADAPTER_PATH}")
        return
    
    try:
        from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
        from peft import PeftModel
        
        print("â³ PHi-4 ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤... (ì•½ 1~2ë¶„ ì†Œìš”)")
        
        base_model_name = "Qwen/Qwen2.5-3B-Instruct"
        
        # 8GB VRAMì„ ìœ„í•œ 4ë¹„íŠ¸ ì–‘ìí™” ì„¤ì •
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_use_double_quant=True,
            bnb_4bit_compute_dtype=torch.float16,
        )
        
        # ì›ë³¸ ëª¨ë¸ ë¡œë“œ
        base_model = AutoModelForCausalLM.from_pretrained(
            base_model_name, quantization_config=bnb_config, device_map="auto"
        )
        chatbot_tokenizer = AutoTokenizer.from_pretrained(base_model_name)
        
        # í•™ìŠµëœ ì–´ëŒ‘í„° í•©ì²´
        chatbot_model = PeftModel.from_pretrained(base_model, str(PHI4_ADAPTER_PATH))
        chatbot_loaded = True
        print("âœ… PHi-4 ëª¨ë¸ ë¡œë”© ì™„ë£Œ! í•œêµ­ì–´ ì¶”ë¡  ì¤€ë¹„ ë.")
        
    except Exception as e:
        print(f"âš ï¸ PHi-4 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")


async def unload_chatbot_model():
    """PHi-4 ëª¨ë¸ ì–¸ë¡œë“œ (ì„œë²„ ì¢…ë£Œ ì‹œ í˜¸ì¶œ)"""
    global chatbot_model, chatbot_tokenizer, chatbot_loaded
    
    if chatbot_model:
        del chatbot_model
        chatbot_model = None
    if chatbot_tokenizer:
        del chatbot_tokenizer
        chatbot_tokenizer = None
    
    chatbot_loaded = False
    torch.cuda.empty_cache()


from pydantic import BaseModel
from typing import List, Optional

class ChatMessage(BaseModel):
    sender: str
    text: str

class ChatRequest(BaseModel):
    prompt: str
    history: Optional[List[ChatMessage]] = None
    client_ip: Optional[str] = None

@router.post("/chat")
async def chat(request: ChatRequest):
    """ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ ëª¨ë¸ì´ ì¶”ë¡ í•˜ê³  ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global chatbot_model, chatbot_tokenizer, chatbot_loaded
    
    if not chatbot_loaded:
        return JSONResponse(
            content={"response": "âš ï¸ ì±—ë´‡ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."},
            status_code=503
        )
    
    try:
        # ë‚ ì”¨ API ë˜ëŠ” ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
        search_context = ""
        searched_web = False
        used_weather_api = False
        user_location = ""
        
        # ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ì¸ ê²½ìš° ê¸°ìƒì²­ API ì‚¬ìš©
        if needs_weather_api(request.prompt):
            print(f"ğŸŒ¤ï¸ ë‚ ì”¨ API í˜¸ì¶œ: {request.prompt}")
            weather_result = await get_weather_info(request.client_ip)
            
            if weather_result and "ì˜¤ë¥˜" not in weather_result:
                used_weather_api = True
                search_context = (
                    f"\n\n[ë‚ ì”¨ ì •ë³´]\n{weather_result}\n"
                    "ìœ„ ë‚ ì”¨ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”."
                )
                print(f"âœ… ë‚ ì”¨ ì •ë³´ íšë“")
        
        # ë‚ ì”¨ ì™¸ ì§ˆë¬¸ì€ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
        elif needs_web_search(request.prompt):
            # ìœ„ì¹˜ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš° IPë¡œ ìœ„ì¹˜ ê°ì§€
            if needs_location_context(request.prompt):
                user_location = get_location_from_ip_sync(request.client_ip)
            
            print(f"ğŸ” ì›¹ ê²€ìƒ‰ ìˆ˜í–‰: {request.prompt}" + (f" (ìœ„ì¹˜: {user_location})" if user_location else ""))
            search_results = search_web(request.prompt, user_location=user_location)
            
            if search_results and "ì˜¤ë¥˜" not in search_results:
                searched_web = True
                search_context = (
                    f"\n\n[ì›¹ ê²€ìƒ‰ ê²°ê³¼]\n{search_results}\n"
                    "ìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."
                )
                print(f"âœ… ê²€ìƒ‰ ê²°ê³¼ íšë“")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë‚ ì”¨ ì •ë³´ ë˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ í¬í•¨)
        if used_weather_api:
            system_prompt = (
                "<|im_start|>system\n"
                "ë‹¹ì‹ ì€ ì¹œê·¼í•œ í•œêµ­ì–´ AI ë‚ ì”¨ ë¹„ì„œì…ë‹ˆë‹¤.\n"
                "ì¤‘ìš”: ì•„ë˜ [ë‚ ì”¨ ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n"
                "ê·œì¹™:\n"
                "1. ë‚ ì”¨ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ì „ë‹¬í•˜ì„¸ìš”.\n"
                "2. ì˜¨ë„, ë‚ ì”¨ ìƒíƒœ, ìŠµë„ ì •ë³´ë¥¼ í¬í•¨í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.\n"
                "3. í•„ìš”ì‹œ ì˜·ì°¨ë¦¼ì´ë‚˜ ìš°ì‚° ë“± ê°„ë‹¨í•œ ì¡°ì–¸ì„ ë§ë¶™ì—¬ë„ ì¢‹ìŠµë‹ˆë‹¤.\n"
                "4. ì´ëª¨ì§€ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."
                f"{search_context}<|im_end|>\n"
            )
        elif searched_web:
            system_prompt = (
                "<|im_start|>system\n"
                "ë‹¹ì‹ ì€ ì •í™•í•œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” í•œêµ­ì–´ AI ë¹„ì„œì…ë‹ˆë‹¤.\n"
                "ì¤‘ìš”: ì•„ë˜ [ì›¹ ê²€ìƒ‰ ê²°ê³¼]ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n"
                "ê·œì¹™:\n"
                "1. ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.\n"
                "2. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‰½ê³  ê°„ë‹¨í•œ ì¼ìƒ ì–¸ì–´ë¡œ ìš”ì•½í•´ì„œ ì „ë‹¬í•˜ì„¸ìš”.\n"
                "3. í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” '~ë¡œ ë³´ì…ë‹ˆë‹¤', '~ë¼ê³  í•©ë‹ˆë‹¤'ì²˜ëŸ¼ í‘œí˜„í•˜ì„¸ìš”.\n"
                "4. URL, ì¶œì²˜, ì´ëª¨ì§€ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n"
                "5. í•µì‹¬ ì •ë³´ë§Œ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."
                f"{search_context}<|im_end|>\n"
            )
        else:
            system_prompt = (
                "<|im_start|>system\n"
                "ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í•œêµ­ì–´ AI ë¹„ì„œì…ë‹ˆë‹¤.\n"
                "ê·œì¹™:\n"
                "1. ì‰½ê³  ê°„ë‹¨í•œ ì¼ìƒ ì–¸ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n"
                "2. í™•ì‹¤íˆ ì•„ëŠ” ì •ë³´ë§Œ ë‹µë³€í•˜ê³ , ëª¨ë¥´ë©´ ì†”ì§íˆ 'ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤'ë¼ê³  í•˜ì„¸ìš”.\n"
                "3. ì‚¬ì‹¤ì´ ì•„ë‹Œ ì •ë³´ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.\n"
                "4. ì´ëª¨ì§€ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.<|im_end|>\n"
            )
        
        # ëŒ€í™” ë‚´ì—­ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        history_prompt = ""
        if request.history:
            for msg in request.history:
                if msg.sender == "user":
                    history_prompt += f"<|im_start|>user\n{msg.text}<|im_end|>\n"
                elif msg.sender == "bot":
                    history_prompt += f"<|im_start|>assistant\n{msg.text}<|im_end|>\n"
        
        # í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸
        user_prompt = f"<|im_start|>user\n{request.prompt}<|im_end|>\n"
        assistant_start = "<|im_start|>assistant\n"
        
        full_prompt = system_prompt + history_prompt + user_prompt + assistant_start
        
        inputs = chatbot_tokenizer(full_prompt, return_tensors="pt").to("cuda")
        
        # ì¶”ë¡  ìƒì„±
        with torch.no_grad():
            outputs = chatbot_model.generate(
                **inputs,
                max_new_tokens=1024,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                eos_token_id=chatbot_tokenizer.eos_token_id,
                pad_token_id=chatbot_tokenizer.eos_token_id,
            )
        
        # ê²°ê³¼ ë””ì½”ë”©
        generated_text = chatbot_tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ë§Œ ì¶”ì¶œ (ë” ê°•ë ¥í•œ íŒŒì‹±)
        final_answer = generated_text
        
        # 1. ë§ˆì§€ë§‰ "assistant" ì´í›„ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if "assistant" in final_answer:
            final_answer = final_answer.split("assistant")[-1].strip()
        
        # 2. "user" ë§ˆì»¤ê°€ ë‚¨ì•„ìˆìœ¼ë©´ ê·¸ ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (ë‹¤ìŒ ëŒ€í™” ì‹œì‘ ì œê±°)
        if "\nuser" in final_answer:
            final_answer = final_answer.split("\nuser")[0].strip()
        if final_answer.startswith("user"):
            # ì²« ì¤„ì´ userë¡œ ì‹œì‘í•˜ë©´ ì œê±°
            lines = final_answer.split("\n")
            final_answer = "\n".join(lines[1:]).strip()
        
        # 3. ì‚¬ìš©ì ì§ˆë¬¸ì´ ë°˜ë³µë˜ë©´ ì œê±°
        if request.prompt in final_answer:
            final_answer = final_answer.replace(request.prompt, "").strip()
        
        # 4. ğŸ” ì´ëª¨ì§€ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ ì œê±° (ê²€ìƒ‰ ì•Œë¦¼ê³¼ ì¤‘ë³µ ë°©ì§€)
        lines = final_answer.split("\n")
        filtered_lines = [line for line in lines if not line.strip().startswith("ğŸ”")]
        final_answer = "\n".join(filtered_lines).strip()
        
        # 5. URL í¬í•¨ ë¬¸ì¥ ì œê±° ë° ì •ë¦¬
        import re
        # URL ì œê±°
        final_answer = re.sub(r'https?://\S+', '', final_answer)
        # "~ì— ê°€ë©´", "~ì—ì„œ" ê°™ì€ ë¶ˆì™„ì „ ì‹œì‘ ì œê±°
        final_answer = re.sub(r'^[\s]*ì—\s+(ê°€ë©´|ë³´ë©´|í™•ì¸)', '', final_answer)
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        final_answer = re.sub(r'\s+', ' ', final_answer).strip()
        # ë¹ˆ ì‘ë‹µì´ë©´ ê¸°ë³¸ ë©”ì‹œì§€
        if not final_answer or len(final_answer) < 10:
            final_answer = "ì£„ì†¡í•©ë‹ˆë‹¤, í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
        
        return JSONResponse(content={
            "response": final_answer,
            "searched_web": searched_web,
            "used_weather_api": used_weather_api
        })
        
    except Exception as e:
        print(f"âš ï¸ ì±—ë´‡ ì¶”ë¡  ì˜¤ë¥˜: {e}")
        return JSONResponse(
            content={"response": f"âš ï¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"},
            status_code=500
        )


@router.get("/chat/status")
async def chat_status():
    """ì±—ë´‡ ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
    return JSONResponse(content={
        "loaded": chatbot_loaded,
        "model_path": str(PHI4_ADAPTER_PATH),
        "model_exists": PHI4_ADAPTER_PATH.exists()
    })
