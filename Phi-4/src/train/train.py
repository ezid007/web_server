import os

# [í•µì‹¬ ì„¤ì • 1] ë©”ëª¨ë¦¬ íŒŒí¸í™” ë°©ì§€
# GPU ë©”ëª¨ë¦¬ê°€ ì¡°ê°ë‚˜ì„œ "ê³µê°„ì€ ë‚¨ëŠ”ë° í° ë©ì–´ë¦¬ë¥¼ ëª» ë„£ëŠ”" í˜„ìƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
# OOM(Out Of Memory) ì—ëŸ¬ë¥¼ ë§‰ëŠ” ì²« ë²ˆì§¸ ë°©ì–´ì„ ì…ë‹ˆë‹¤.
os.environ["PYTORCH_ALLOC_CONF"] = "expandable_segments:True"

import torch
from datasets import load_dataset
from transformers import (
    AutoModelForCausalLM,  # í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ ë¡œë”
    AutoTokenizer,  # í…ìŠ¤íŠ¸ <-> ìˆ«ì ë³€í™˜ê¸°
    BitsAndBytesConfig,  # ëª¨ë¸ ì••ì¶•(ì–‘ìí™”) ì„¤ì • ë„êµ¬
)
from peft import (
    LoraConfig,
    prepare_model_for_kbit_training,
)  # LoRA(ê°€ì¤‘ì¹˜ íŠœë‹) ê´€ë ¨ ë„êµ¬
from trl import SFTTrainer, SFTConfig  # ì‹¤ì œ í•™ìŠµì„ ìˆ˜í–‰í•˜ëŠ” íŠ¸ë ˆì´ë„ˆ


def main():
    # ============================================================
    # 1. ê¸°ë³¸ ì„¤ì • (Configuration)
    # ============================================================
    model_name = "Qwen/Qwen2.5-3B-Instruct"  # í•™ìŠµì‹œí‚¬ í•™ìƒ ëª¨ë¸ (30ì–µ íŒŒë¼ë¯¸í„°)
    dataset_path = "data/synthetic/train.jsonl"  # ìš°ë¦¬ê°€ ë§Œë“  êµê³¼ì„œ (í•©ì„± ë°ì´í„°)
    output_dir = "models/phi-4-3b-reasoning"  # í•™ìŠµ ê²°ê³¼ê°€ ì €ì¥ë  í´ë”

    # GPU ìºì‹œ ì²­ì†Œ: í˜¹ì‹œ ë‚¨ì•„ìˆì„ì§€ ëª¨ë¥¼ ì“°ë ˆê¸° ë°ì´í„°ë¥¼ ë¹„ì›ë‹ˆë‹¤.
    torch.cuda.empty_cache()

    # ============================================================
    # 2. ë°ì´í„° ì¤€ë¹„ (Data Preparation)
    # ============================================================
    print(f"ğŸ“š Loading dataset from {dataset_path}...")
    dataset = load_dataset("json", data_files=dataset_path, split="train")

    # ë°ì´í„°ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” 'ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸'ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    def format_instruction(sample):
        # ë‹¨ê³„ë³„ ì¶”ë¡ (Reasoning Steps) ë¦¬ìŠ¤íŠ¸ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°í•˜ì—¬ í•˜ë‚˜ì˜ ê¸´ ê¸€ë¡œ ë§Œë“­ë‹ˆë‹¤.
        steps = "\n".join(
            [f"{i+1}. {step}" for i, step in enumerate(sample["reasoning_steps"])]
        )

        # [í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§]
        # Phi-4 ë…¼ë¬¸ì˜ í•µì‹¬ì¸ "ChatML" í¬ë§·ì„ ì ìš©í•©ë‹ˆë‹¤.
        # System: ì—­í•  ë¶€ì—¬ / User: ì§ˆë¬¸ / Assistant: ì‚¬ê³  ê³¼ì • + ì •ë‹µ
        prompt = (
            f"<|im_start|>system\nYou are a helpful assistant capable of complex reasoning.<|im_end|>\n"
            f"<|im_start|>user\n{sample['question']}<|im_end|>\n"
            f"<|im_start|>assistant\nLet's think step by step.\n\n{steps}\n\n**Answer:** {sample['answer']}<|im_end|>"
        )
        # [ì£¼ì˜] ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ë¬¸ìì—´ ìì²´ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
        return prompt

    # ============================================================
    # 3. ëª¨ë¸ ì••ì¶• ì„¤ì • (Quantization)
    # ============================================================
    # 8GB VRAMì— ëª¨ë¸ì„ ì˜¬ë¦¬ê¸° ìœ„í•œ í•„ìˆ˜ ì„¤ì •ì…ë‹ˆë‹¤.
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,  # ëª¨ë¸ì„ 4ë¹„íŠ¸ë¡œ ì••ì¶•í•´ì„œ ë¡œë”© (ìš©ëŸ‰ ì•½ 1/4ë¡œ ê°ì†Œ)
        bnb_4bit_quant_type="nf4",  # 4ë¹„íŠ¸ ì¤‘ì—ì„œë„ ì„±ëŠ¥ ì†ì‹¤ì´ ì ì€ 'NF4' ë°©ì‹ ì‚¬ìš©
        bnb_4bit_use_double_quant=True,  # ì´ì¤‘ ì••ì¶• ê¸°ìˆ ë¡œ ë©”ëª¨ë¦¬ë¥¼ í•œ ë²ˆ ë” ì ˆì•½
        bnb_4bit_compute_dtype=torch.float16,  # ì—°ì‚° ì†ë„ë¥¼ ìœ„í•´ ê³„ì‚°ì€ 16ë¹„íŠ¸ë¡œ ìˆ˜í–‰
        llm_int8_enable_fp32_cpu_offload=True,  # VRAM ë¶€ì¡± ì‹œ ì‹œìŠ¤í…œ RAM(64GB)ì„ ë¹Œë ¤ ì”€
    )

    print(f"ğŸ¤– Loading Student Model: {model_name}")
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=bnb_config,  # ìœ„ì—ì„œ ì •ì˜í•œ ì••ì¶• ì„¤ì • ì ìš©
        device_map="auto",  # GPU/CPU ìë™ í• ë‹¹
        use_cache=False,  # í•™ìŠµ ì¤‘ì—ëŠ” ê³¼ê±° ê¸°ì–µ ìºì‹±ì„ êº¼ì„œ ë©”ëª¨ë¦¬ ì ˆì•½
    )

    # ëª¨ë¸ì„ í•™ìŠµ ê°€ëŠ¥í•œ ìƒíƒœë¡œ ì „ì²˜ë¦¬í•˜ê³ , Gradient Checkpointingì„ ì¼­ë‹ˆë‹¤.
    # Gradient Checkpointing: ì¤‘ê°„ ê³„ì‚° ê²°ê³¼ë¥¼ ì €ì¥ ì•ˆ í•˜ê³  í•„ìš”í•  ë•Œ ë‹¤ì‹œ ê³„ì‚° (ì†ë„â†“ ë©”ëª¨ë¦¬ íš¨ìœ¨â†‘)
    model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)

    # ============================================================
    # 4. í† í¬ë‚˜ì´ì € ì„¤ì • (Tokenizer)
    # ============================================================
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    tokenizer.pad_token = (
        tokenizer.eos_token
    )  # ë¬¸ì¥ ê¸¸ì´ë¥¼ ë§ì¶œ ë•Œ ë¹ˆ ê³µê°„ì„ EOS(ë¬¸ì¥ë) í† í°ìœ¼ë¡œ ì±„ì›€
    tokenizer.padding_side = "right"  # ì˜¤ë¥¸ìª½ ë¹ˆ ê³µê°„ì„ ì±„ì›€

    # [í•µì‹¬ ìˆ˜ì •] ë©”ëª¨ë¦¬ í­ë°œ ë°©ì§€ìš© ê¸¸ì´ ì œí•œ
    # 512 í† í°ì´ ë„˜ì–´ê°€ë©´ ê°€ì°¨ ì—†ì´ ìë¦…ë‹ˆë‹¤. OOM í•´ê²°ì˜ ì¼ë“±ê³µì‹ ì…ë‹ˆë‹¤.
    tokenizer.model_max_length = 512

    # ============================================================
    # 5. LoRA ì„¤ì • (Low-Rank Adaptation)
    # ============================================================
    # ëª¨ë¸ ì „ì²´ë¥¼ í•™ìŠµí•˜ëŠ” ê±´ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ, ì–‡ì€ 'ì–´ëŒ‘í„°'ë§Œ ë¶™ì—¬ì„œ í•™ìŠµí•©ë‹ˆë‹¤.
    peft_config = LoraConfig(
        r=16,  # ì–´ëŒ‘í„°ì˜ ë‘ê»˜ (Rank). ë†’ì„ìˆ˜ë¡ ë˜‘ë˜‘í•´ì§€ì§€ë§Œ ë©”ëª¨ë¦¬ë¥¼ ë” ì”€.
        lora_alpha=32,  # í•™ìŠµ ë°˜ì˜ë¥ . ë³´í†µ rì˜ 2ë°°ë¡œ ì„¤ì •.
        lora_dropout=0.05,  # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ ëœë¤í•˜ê²Œ ì¼ë¶€ ë‰´ëŸ°ì„ ë”.
        bias="none",
        task_type="CAUSAL_LM",
        # í•™ìŠµì‹œí‚¬ íƒ€ê²Ÿ ë ˆì´ì–´ë“¤ (Qwen ëª¨ë¸ì˜ ëª¨ë“  ì£¼ìš” ì—°ì‚° ë¶€ìœ„)
        target_modules=[
            "q_proj",
            "k_proj",
            "v_proj",
            "o_proj",
            "gate_proj",
            "up_proj",
            "down_proj",
        ],
    )

    # ============================================================
    # 6. í•™ìŠµ ì‹¤í–‰ ì„¤ì • (Training Arguments)
    # ============================================================
    training_args = SFTConfig(
        output_dir=output_dir,
        # [ë©”ëª¨ë¦¬ ìµœì í™”ì˜ ëíŒì™• ì„¤ì •]
        per_device_train_batch_size=1,  # í•œ ë²ˆì— ë”± 1ë¬¸ì œë§Œ í’‰ë‹ˆë‹¤. (ê°€ì¥ ì•ˆì „)
        gradient_accumulation_steps=8,  # ëŒ€ì‹  8ë²ˆ í‘¼ ê²°ê³¼ë¥¼ ëª¨ì•„ì„œ í•œ ë²ˆì— ì—…ë°ì´íŠ¸ (ë°°ì¹˜ ì‚¬ì´ì¦ˆ 8 íš¨ê³¼)
        learning_rate=2e-4,  # í•™ìŠµ ì†ë„ (ë„ˆë¬´ ë¹ ë¥´ë©´ ë©ì²­í•´ì§€ê³ , ë„ˆë¬´ ëŠë¦¬ë©´ ë‹µë‹µí•¨)
        logging_steps=1,  # 1ìŠ¤í…ë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥ (ì‹¤ì‹œê°„ í™•ì¸ìš©)
        num_train_epochs=3,  # ê°™ì€ ë¬¸ì œì§‘ì„ 3ë²ˆ ë°˜ë³µ í•™ìŠµ
        fp16=True,  # 16ë¹„íŠ¸ ì—°ì‚° ì‚¬ìš© (ì†ë„ í–¥ìƒ)
        save_strategy="epoch",  # 1 Epoch ëë‚  ë•Œë§ˆë‹¤ ì €ì¥
        optim="paged_adamw_8bit",  # [ì¤‘ìš”] ì˜µí‹°ë§ˆì´ì €ë„ ì••ì¶•í•´ì„œ ë©”ëª¨ë¦¬ ì ˆì•½
        gradient_checkpointing=True,  # ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œ í™œì„±í™”
        max_grad_norm=0.3,  # í•™ìŠµì´ íŠ€ëŠ” ê²ƒì„ ë°©ì§€ (ì•ˆì „ì¥ì¹˜)
        warmup_ratio=0.03,  # ì´ˆë°˜ 3%ëŠ” ì²œì²œíˆ í•™ìŠµí•˜ë©° ì˜ˆì—´
        lr_scheduler_type="constant",  # í•™ìŠµë¥ ì„ ì¼ì •í•˜ê²Œ ìœ ì§€
        packing=False,  # ë°ì´í„°ë¥¼ ê½‰ ì±„ìš°ì§€ ì•ŠìŒ (ë©”ëª¨ë¦¬ ì•ˆì „ ìš°ì„ )
        dataset_text_field="text",  # ë°ì´í„°ì…‹ í•„ë“œëª… (í˜•ì‹ìƒ í•„ìš”)
    )

    # ============================================================
    # 7. íŠ¸ë ˆì´ë„ˆ ì‹¤í–‰ (Run Training)
    # ============================================================
    trainer = SFTTrainer(
        model=model,  # í•™ìƒ (Qwen 3B)
        train_dataset=dataset,  # êµì¬ (í•©ì„± ë°ì´í„°)
        peft_config=peft_config,  # í•™ìŠµë²• (LoRA)
        formatting_func=format_instruction,  # ë°ì´í„° ê°€ê³µ í•¨ìˆ˜
        args=training_args,  # í•™ìŠµ ê³„íší‘œ
        processing_class=tokenizer,  # í†µì—­ì‚¬
    )

    print("ğŸš€ Starting 3B Model Training (Final Fix)...")
    trainer.train()  # ì‹¤ì œ í•™ìŠµ ì‹œì‘!

    # í•™ìŠµ ì™„ë£Œ í›„ ì €ì¥
    print(f"ğŸ’¾ Saving adapter to {output_dir}")
    trainer.model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)


if __name__ == "__main__":
    main()
