#!/usr/bin/env python3
"""
ìº¡ì²˜ ë° ìë™ ë¼ë²¨ë§ ìŠ¤í¬ë¦½íŠ¸
TurtleBot3 ì¹´ë©”ë¼ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìº¡ì²˜í•˜ê³ 
YOLOv11nìœ¼ë¡œ ì‚¬ëŒì„ íƒì§€í•˜ì—¬ ìë™ìœ¼ë¡œ ë¼ë²¨ì„ ìƒì„±í•©ë‹ˆë‹¤.

ë‘ ê°€ì§€ ëª¨ë“œ ì§€ì›:
1. ROS2 ì§ì ‘ êµ¬ë… ëª¨ë“œ (--ros2): ROS2 í† í”½ì—ì„œ ì§ì ‘ ì˜ìƒ ìˆ˜ì‹  (ê¶Œì¥, ë¹ ë¦„)
2. HTTP ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ (ê¸°ë³¸): web_serverì˜ /camera/raw ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
"""

import os
import cv2
import yaml
import time
import argparse
import threading
import queue
from datetime import datetime
from pathlib import Path
from ultralytics import YOLO
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_DIR = Path(__file__).parent.parent
WEB_SERVER_DIR = PROJECT_DIR.parent  # web_server ë””ë ‰í† ë¦¬
DATASET_DIR = PROJECT_DIR / "dataset"
IMAGES_DIR = DATASET_DIR / "images"
LABELS_DIR = DATASET_DIR / "labels"
CLASSES_FILE = PROJECT_DIR / "classes.yaml"

# .env íŒŒì¼ ë¡œë“œ
load_dotenv(WEB_SERVER_DIR / ".env")

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
TURTLEBOT_IP = os.getenv("TURTLEBOT_IP")
WEB_SERVER_PORT = os.getenv("PORT")
CAMERA_TOPIC = os.getenv("CAMERA_TOPIC", "/camera_node/image_raw")
DEFAULT_STREAM_URL = f"http://localhost:{WEB_SERVER_PORT}/camera/raw"


class ROS2CameraReader:
    """
    ROS2 í† í”½ì—ì„œ ì§ì ‘ ì¹´ë©”ë¼ ì˜ìƒì„ ì½ëŠ” ë¦¬ë”
    HTTP ì˜¤ë²„í—¤ë“œ ì—†ì´ ìµœê³  ì„±ëŠ¥ ì œê³µ
    """

    def __init__(self, topic: str = None):
        self.topic = topic or CAMERA_TOPIC
        self.frame = None
        self.running = False
        self.lock = threading.Lock()
        self.node = None
        self.thread = None

    def start(self) -> bool:
        """ROS2 ë…¸ë“œ ì‹œì‘"""
        try:
            import rclpy
            from rclpy.node import Node
            from sensor_msgs.msg import Image
            from cv_bridge import CvBridge

            self.rclpy = rclpy
            self.bridge = CvBridge()

            # ROS2 ì´ˆê¸°í™” (ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìœ¼ë©´ ê±´ë„ˆëœ€)
            try:
                rclpy.init()
            except RuntimeError:
                pass  # ì´ë¯¸ ì´ˆê¸°í™”ë¨

            # ê°„ë‹¨í•œ ë…¸ë“œ í´ë˜ìŠ¤ ì •ì˜
            class CameraNode(Node):
                def __init__(node_self, topic, callback):
                    super().__init__("auto_labeling_camera_node")
                    node_self.subscription = node_self.create_subscription(
                        Image, topic, callback, 10
                    )

            self.running = True
            self.node = CameraNode(self.topic, self._camera_callback)

            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ spin
            self.thread = threading.Thread(target=self._spin_thread, daemon=True)
            self.thread.start()

            print(f"âœ… ROS2 ì¹´ë©”ë¼ í† í”½ êµ¬ë… ì‹œì‘: {self.topic}")
            return True

        except ImportError as e:
            print(f"âŒ ROS2ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return False
        except Exception as e:
            print(f"âŒ ROS2 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def _spin_thread(self):
        """ROS2 spinì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰"""
        self.rclpy.spin(self.node)

    def _camera_callback(self, msg):
        """ì¹´ë©”ë¼ ë©”ì‹œì§€ ì½œë°±"""
        try:
            if msg.encoding == "rgb8":
                cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")
            else:
                cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")

            # 640x480ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            if cv_image.shape[1] != 640 or cv_image.shape[0] != 480:
                cv_image = cv2.resize(cv_image, (640, 480))

            with self.lock:
                self.frame = cv_image
        except Exception as e:
            print(f"âš ï¸ í”„ë ˆì„ ë³€í™˜ ì˜¤ë¥˜: {e}")

    def read(self):
        """ìµœì‹  í”„ë ˆì„ ë°˜í™˜"""
        with self.lock:
            return self.frame.copy() if self.frame is not None else None

    def stop(self):
        """ROS2 ë…¸ë“œ ì •ì§€"""
        self.running = False
        if self.node:
            self.node.destroy_node()
        try:
            self.rclpy.shutdown()
        except:
            pass


class VideoStreamReader:
    """
    ë¹„ë™ê¸° ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ë¦¬ë”
    OpenCVì˜ ë²„í¼ë§ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ í”„ë ˆì„ì„ ì½ìŒ
    í•­ìƒ ìµœì‹  í”„ë ˆì„ë§Œ ìœ ì§€í•˜ì—¬ ì§€ì—° ë°©ì§€
    """

    def __init__(self, stream_url: str):
        self.stream_url = stream_url
        self.frame = None
        self.running = False
        self.lock = threading.Lock()
        self.cap = None
        self.thread = None

    def start(self) -> bool:
        """ìŠ¤íŠ¸ë¦¼ ì‹œì‘"""
        self.cap = cv2.VideoCapture(self.stream_url)

        # MJPEG ìŠ¤íŠ¸ë¦¼ ìµœì í™” ì„¤ì •
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ ìµœì†Œí™”

        if not self.cap.isOpened():
            return False

        self.running = True
        self.thread = threading.Thread(target=self._reader_loop, daemon=True)
        self.thread.start()
        return True

    def _reader_loop(self):
        """í”„ë ˆì„ ì½ê¸° ë£¨í”„ (ë³„ë„ ìŠ¤ë ˆë“œ)"""
        while self.running:
            ret, frame = self.cap.read()
            if ret:
                with self.lock:
                    self.frame = frame
            else:
                # ì—°ê²° ëŠê¹€ ì‹œ ì¬ì—°ê²° ì‹œë„
                time.sleep(0.5)
                self.cap.release()
                self.cap = cv2.VideoCapture(self.stream_url)
                self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

    def read(self):
        """ìµœì‹  í”„ë ˆì„ ë°˜í™˜ (Noneì´ë©´ í”„ë ˆì„ ì—†ìŒ)"""
        with self.lock:
            return self.frame.copy() if self.frame is not None else None

    def stop(self):
        """ìŠ¤íŠ¸ë¦¼ ì •ì§€"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=1.0)
        if self.cap:
            self.cap.release()


def load_classes():
    """classes.yamlì—ì„œ í´ë˜ìŠ¤ ëª©ë¡ ë¡œë“œ"""
    if CLASSES_FILE.exists():
        with open(CLASSES_FILE, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
            return data.get("names", ["unknown"])
    return ["unknown"]


def save_classes(classes: list):
    """classes.yamlì— í´ë˜ìŠ¤ ëª©ë¡ ì €ì¥"""
    data = {
        "path": str(DATASET_DIR),
        "train": "images",
        "val": "images",
        "nc": len(classes),
        "names": classes,
    }
    with open(CLASSES_FILE, "w", encoding="utf-8") as f:
        yaml.dump(data, f, allow_unicode=True, default_flow_style=False)


def add_new_person(name: str):
    """ìƒˆë¡œìš´ ì‚¬ëŒ í´ë˜ìŠ¤ ì¶”ê°€"""
    classes = load_classes()
    if name not in classes:
        classes.append(name)
        save_classes(classes)
        print(f"âœ… ìƒˆë¡œìš´ í´ë˜ìŠ¤ ì¶”ê°€ë¨: '{name}' (ID: {len(classes) - 1})")
    return classes.index(name)


def calculate_iou(box1, box2):
    """
    ë‘ ë°”ìš´ë”© ë°•ìŠ¤ì˜ IoU(Intersection over Union) ê³„ì‚°
    box í˜•ì‹: (x_center, y_center, width, height) - ì •ê·œí™”ëœ ì¢Œí‘œ
    """
    # ë°•ìŠ¤ë¥¼ (x1, y1, x2, y2) í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    x1_1 = box1[0] - box1[2] / 2
    y1_1 = box1[1] - box1[3] / 2
    x2_1 = box1[0] + box1[2] / 2
    y2_1 = box1[1] + box1[3] / 2

    x1_2 = box2[0] - box2[2] / 2
    y1_2 = box2[1] - box2[3] / 2
    x2_2 = box2[0] + box2[2] / 2
    y2_2 = box2[1] + box2[3] / 2

    # êµì§‘í•© ì˜ì—­ ê³„ì‚°
    inter_x1 = max(x1_1, x1_2)
    inter_y1 = max(y1_1, y1_2)
    inter_x2 = min(x2_1, x2_2)
    inter_y2 = min(y2_1, y2_2)

    if inter_x2 <= inter_x1 or inter_y2 <= inter_y1:
        return 0.0

    inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)

    # í•©ì§‘í•© ì˜ì—­ ê³„ì‚°
    box1_area = box1[2] * box1[3]
    box2_area = box2[2] * box2[3]
    union_area = box1_area + box2_area - inter_area

    if union_area == 0:
        return 0.0

    return inter_area / union_area


def is_scene_changed(current_detections, previous_detections, iou_threshold=0.85):
    """
    í˜„ì¬ íƒì§€ ê²°ê³¼ê°€ ì´ì „ê³¼ ì¶©ë¶„íˆ ë‹¤ë¥¸ì§€ í™•ì¸
    
    Args:
        current_detections: í˜„ì¬ í”„ë ˆì„ì˜ íƒì§€ ê²°ê³¼
        previous_detections: ì´ì „ ì €ì¥ëœ í”„ë ˆì„ì˜ íƒì§€ ê²°ê³¼
        iou_threshold: ì´ ê°’ë³´ë‹¤ IoUê°€ ë†’ìœ¼ë©´ ë™ì¼í•œ ìœ„ì¹˜ë¡œ íŒë‹¨
    
    Returns:
        True: ì¥ë©´ì´ ë³€ê²½ë¨ (ì €ì¥í•´ì•¼ í•¨)
        False: ì¥ë©´ì´ ìœ ì‚¬í•¨ (ì €ì¥ ê±´ë„ˆëœ€)
    """
    # ì´ì „ íƒì§€ê°€ ì—†ìœ¼ë©´ ë³€ê²½ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
    if not previous_detections:
        return True
    
    # íƒì§€ ìˆ˜ê°€ ë‹¤ë¥´ë©´ ë³€ê²½ëœ ê²ƒ
    if len(current_detections) != len(previous_detections):
        return True
    
    # ê° íƒì§€ì— ëŒ€í•´ IoU í™•ì¸
    for curr_det in current_detections:
        curr_box = (curr_det['x_center'], curr_det['y_center'], 
                    curr_det['width'], curr_det['height'])
        
        # í˜„ì¬ íƒì§€ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì´ì „ íƒì§€ ì°¾ê¸°
        max_iou = 0
        for prev_det in previous_detections:
            prev_box = (prev_det['x_center'], prev_det['y_center'],
                        prev_det['width'], prev_det['height'])
            iou = calculate_iou(curr_box, prev_box)
            max_iou = max(max_iou, iou)
        
        # IoUê°€ ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ìœ„ì¹˜ê°€ ë³€ê²½ëœ ê²ƒ
        if max_iou < iou_threshold:
            return True
    
    # ëª¨ë“  íƒì§€ê°€ ìœ ì‚¬í•œ ìœ„ì¹˜ì— ìˆìœ¼ë©´ ë³€ê²½ ì—†ìŒ
    return False


def capture_and_label(
    stream_url: str,
    model_path: str = "yolo11n.pt",
    target_class_id: int = 0,
    save_interval: float = 1.0,
    confidence_threshold: float = 0.5,
    skip_frames: int = 0,
    use_ros2: bool = False,
):
    """
    ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìº¡ì²˜í•˜ê³  ìë™ìœ¼ë¡œ ë¼ë²¨ë§

    Args:
        stream_url: MJPEG ìŠ¤íŠ¸ë¦¼ URL (HTTP ëª¨ë“œì—ì„œ ì‚¬ìš©)
        model_path: YOLO ëª¨ë¸ ê²½ë¡œ
        target_class_id: ì €ì¥í•  í´ë˜ìŠ¤ ID (0=unknown, 1=ì²«ë²ˆì§¸ ì‚¬ëŒ, ...)
        save_interval: ì €ì¥ ê°„ê²© (ì´ˆ)
        confidence_threshold: íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’
        skip_frames: YOLO ì¶”ë¡ ì„ ê±´ë„ˆë›¸ í”„ë ˆì„ ìˆ˜ (0=ë§¤ í”„ë ˆì„ ì¶”ë¡ )
        use_ros2: ROS2 í† í”½ì—ì„œ ì§ì ‘ ì½ê¸° (True=ROS2, False=HTTP)
    """
    import torch

    # ë””ë ‰í† ë¦¬ ìƒì„±
    IMAGES_DIR.mkdir(parents=True, exist_ok=True)
    LABELS_DIR.mkdir(parents=True, exist_ok=True)

    # CUDA í™•ì¸
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {device.upper()}")
    if device == "cuda":
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(
            f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB"
        )

    # YOLO ëª¨ë¸ ë¡œë“œ (GPU ëª…ì‹œ)
    print(f"ğŸ”„ YOLO ëª¨ë¸ ë¡œë”© ì¤‘: {model_path}")
    model = YOLO(model_path)
    model.to(device)

    # ì›Œë°ì—… (ì²« ì¶”ë¡ ì€ ëŠë¦´ ìˆ˜ ìˆìŒ)
    print("ğŸ”¥ GPU ì›Œë°ì—… ì¤‘...")
    dummy = (
        cv2.imread(str(PROJECT_DIR / "scripts" / "warmup.jpg"))
        if (PROJECT_DIR / "scripts" / "warmup.jpg").exists()
        else None
    )
    if dummy is None:
        dummy = (torch.rand(1, 3, 480, 640) * 255).byte().numpy()[0].transpose(1, 2, 0)
    model(dummy, verbose=False)
    print("âœ… ì›Œë°ì—… ì™„ë£Œ")

    # ì¹´ë©”ë¼ ë¦¬ë” ì‹œì‘ (ROS2 ë˜ëŠ” HTTP)
    if use_ros2:
        print(f"ğŸ“· ROS2 ì¹´ë©”ë¼ í† í”½ ì—°ê²° ì¤‘: {CAMERA_TOPIC}")
        stream_reader = ROS2CameraReader(CAMERA_TOPIC)
    else:
        print(f"ğŸ“· HTTP ìŠ¤íŠ¸ë¦¼ ì—°ê²° ì¤‘: {stream_url}")
        stream_reader = VideoStreamReader(stream_url)

    if not stream_reader.start():
        print("âŒ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return

    # ì²« í”„ë ˆì„ ëŒ€ê¸°
    print("â³ ì²« í”„ë ˆì„ ëŒ€ê¸° ì¤‘...")
    for _ in range(30):  # ìµœëŒ€ 3ì´ˆ ëŒ€ê¸°
        if stream_reader.read() is not None:
            break
        time.sleep(0.1)

    print("\n" + "=" * 50)
    print("ğŸ¯ ìë™ ë¼ë²¨ë§ ì‹œì‘!")
    print("=" * 50)
    print("ì¡°ì‘ ë°©ë²•:")
    print("  [SPACE] - í˜„ì¬ í”„ë ˆì„ ì €ì¥ (ì‚¬ëŒ íƒì§€ ì‹œ)")
    print("  [B] - ë°°ê²½ ì´ë¯¸ì§€ ì €ì¥ (ë¹ˆ ë¼ë²¨)")
    print("  [A] - ìë™ ì €ì¥ ëª¨ë“œ í† ê¸€")
    print("  [N] - ìƒˆë¡œìš´ ì‚¬ëŒ í´ë˜ìŠ¤ ì¶”ê°€")
    print("  [1-9] - í´ë˜ìŠ¤ ID ë³€ê²½")
    print("  [Q] - ì¢…ë£Œ")
    print("=" * 50 + "\n")

    classes = load_classes()
    print(f"ğŸ“‹ í˜„ì¬ í´ë˜ìŠ¤ ëª©ë¡: {classes}")
    print(f"ğŸ·ï¸  í˜„ì¬ ì €ì¥ í´ë˜ìŠ¤: {classes[target_class_id]} (ID: {target_class_id})")

    auto_save = False
    last_save_time = 0
    image_count = len(list(IMAGES_DIR.glob("*.jpg")))
    frame_count = 0
    last_detections = []
    last_saved_detections = []  # ë§ˆì§€ë§‰ìœ¼ë¡œ ì €ì¥ëœ íƒì§€ ê²°ê³¼
    skip_count = 0  # ìœ ì‚¬ë„ë¡œ ì¸í•´ ê±´ë„ˆë›´ íšŸìˆ˜
    target_fps = 30  # ëª©í‘œ FPS
    frame_interval = 1.0 / target_fps  # í”„ë ˆì„ ê°„ê²© (ì•½ 33ms)
    last_frame_time = time.time()

    try:
        while True:
            # FPS ì œí•œ (30 FPS)
            current_time = time.time()
            elapsed = current_time - last_frame_time
            if elapsed < frame_interval:
                time.sleep(frame_interval - elapsed)
                current_time = time.time()
            last_frame_time = current_time

            frame = stream_reader.read()
            if frame is None:
                time.sleep(0.01)
                continue

            frame_count += 1



            # YOLO ì¶”ë¡  (skip_framesì— ë”°ë¼ ê±´ë„ˆë›°ê¸°)
            if skip_frames == 0 or frame_count % (skip_frames + 1) == 0:
                results = model(
                    frame, conf=confidence_threshold, classes=[0], verbose=False
                )

                # íƒì§€ ê²°ê³¼ ì²˜ë¦¬
                detections = []
                for result in results:
                    boxes = result.boxes
                    for box in boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                        conf = box.conf[0].cpu().numpy()

                        h, w = frame.shape[:2]
                        x_center = ((x1 + x2) / 2) / w
                        y_center = ((y1 + y2) / 2) / h
                        box_width = (x2 - x1) / w
                        box_height = (y2 - y1) / h

                        detections.append(
                            {
                                "class_id": target_class_id,
                                "x_center": x_center,
                                "y_center": y_center,
                                "width": box_width,
                                "height": box_height,
                                "confidence": conf,
                                "bbox": (x1, y1, x2, y2),
                            }
                        )
                last_detections = detections
            else:
                detections = last_detections

            # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
            display_frame = frame.copy()
            for det in detections:
                x1, y1, x2, y2 = det["bbox"]
                conf = det["confidence"]

                color = (0, 255, 0) if conf > 0.7 else (0, 255, 255)
                cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)

                label = f"{classes[target_class_id]}: {conf:.2f}"
                cv2.putText(
                    display_frame,
                    label,
                    (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    color,
                    2,
                )

            # ìƒíƒœ í‘œì‹œ
            status_text = f"Class: {classes[target_class_id]} | Auto: {'ON' if auto_save else 'OFF'} | Saved: {image_count}"
            cv2.putText(
                display_frame,
                status_text,
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2,
            )

            # í™”ë©´ í‘œì‹œ
            cv2.imshow("Auto Labeling (Press Q to quit)", display_frame)

            # ìë™ ì €ì¥ ëª¨ë“œ
            should_save = False

            if auto_save and len(detections) > 0:
                if current_time - last_save_time >= save_interval:
                    # ìœ ì‚¬ë„ ì²´í¬: ì¥ë©´ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ì €ì¥
                    if is_scene_changed(detections, last_saved_detections):
                        should_save = True
                        last_save_time = current_time
                    else:
                        skip_count += 1

            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF

            if key == ord("q"):
                break
            elif key == ord(" "):  # SPACE - ìˆ˜ë™ ì €ì¥
                if len(detections) > 0:
                    should_save = True
                else:
                    print("âš ï¸ ì‚¬ëŒì´ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            elif key == ord("a"):  # A - ìë™ ì €ì¥ í† ê¸€
                auto_save = not auto_save
                print(f"ğŸ”„ ìë™ ì €ì¥ ëª¨ë“œ: {'ON' if auto_save else 'OFF'}")
            elif key == ord("n"):  # N - ìƒˆë¡œìš´ ì‚¬ëŒ ì¶”ê°€
                cv2.destroyAllWindows()
                name = input("ìƒˆë¡œìš´ ì‚¬ëŒ ì´ë¦„ ì…ë ¥: ").strip()
                if name:
                    target_class_id = add_new_person(name)
                    classes = load_classes()
                cv2.namedWindow("Auto Labeling (Press Q to quit)")
            elif key == ord("b"):  # B - ë°°ê²½ ì´ë¯¸ì§€ ì €ì¥ (ë¹ˆ ë¼ë²¨)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                image_filename = f"background_{timestamp}.jpg"
                label_filename = f"background_{timestamp}.txt"

                # ì´ë¯¸ì§€ ì €ì¥
                cv2.imwrite(str(IMAGES_DIR / image_filename), frame)

                # ë¹ˆ ë¼ë²¨ íŒŒì¼ ì €ì¥
                with open(LABELS_DIR / label_filename, "w") as f:
                    pass  # ë¹ˆ íŒŒì¼

                image_count += 1
                print(f"ğŸ–¼ï¸  ë°°ê²½ ì €ì¥ë¨: {image_filename}")
            elif ord("1") <= key <= ord("9"):  # 1-9 - í´ë˜ìŠ¤ ë³€ê²½
                new_id = key - ord("1")
                if new_id < len(classes):
                    target_class_id = new_id
                    print(
                        f"ğŸ·ï¸  í´ë˜ìŠ¤ ë³€ê²½: {classes[target_class_id]} (ID: {target_class_id})"
                    )

            # ì´ë¯¸ì§€ ë° ë¼ë²¨ ì €ì¥
            if should_save:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                class_name = classes[target_class_id]
                image_filename = f"{class_name}_{timestamp}.jpg"
                label_filename = f"{class_name}_{timestamp}.txt"

                # ì´ë¯¸ì§€ ì €ì¥
                cv2.imwrite(str(IMAGES_DIR / image_filename), frame)

                # ë¼ë²¨ ì €ì¥ (YOLO í¬ë§·)
                with open(LABELS_DIR / label_filename, "w") as f:
                    for det in detections:
                        line = f"{det['class_id']} {det['x_center']:.6f} {det['y_center']:.6f} {det['width']:.6f} {det['height']:.6f}\n"
                        f.write(line)

                image_count += 1
                last_saved_detections = detections.copy()  # ì €ì¥ëœ íƒì§€ ê²°ê³¼ ê¸°ë¡
                print(f"ğŸ’¾ ì €ì¥ë¨: {image_filename} (íƒì§€: {len(detections)}ê°œ)")

    finally:
        stream_reader.stop()
        cv2.destroyAllWindows()

    print(f"\nâœ… ì™„ë£Œ! ì´ {image_count}ì¥ì˜ ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   ğŸ“ ì´ë¯¸ì§€: {IMAGES_DIR}")
    print(f"   ğŸ“ ë¼ë²¨: {LABELS_DIR}")


def main():
    parser = argparse.ArgumentParser(description="YOLO ê¸°ë°˜ ìë™ ë¼ë²¨ë§ ë„êµ¬")
    parser.add_argument(
        "--stream", "-s", default=DEFAULT_STREAM_URL, help="ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ URL"
    )
    parser.add_argument("--model", "-m", default="yolo11n.pt", help="YOLO ëª¨ë¸ ê²½ë¡œ")
    parser.add_argument(
        "--class-id",
        "-c",
        type=int,
        default=0,
        help="ì €ì¥í•  í´ë˜ìŠ¤ ID (ê¸°ë³¸: 0=unknown)",
    )
    parser.add_argument(
        "--interval", "-i", type=float, default=1.0, help="ìë™ ì €ì¥ ê°„ê²© (ì´ˆ)"
    )
    parser.add_argument(
        "--confidence", "-t", type=float, default=0.5, help="íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’"
    )
    parser.add_argument(
        "--skip-frames",
        "-k",
        type=int,
        default=0,
        help="YOLO ì¶”ë¡ ì„ ê±´ë„ˆë›¸ í”„ë ˆì„ ìˆ˜ (0=ë§¤ í”„ë ˆì„, 1=2í”„ë ˆì„ë§ˆë‹¤, 2=3í”„ë ˆì„ë§ˆë‹¤...)",
    )
    parser.add_argument(
        "--ros2",
        "-r",
        action="store_true",
        help="ROS2 í† í”½ì—ì„œ ì§ì ‘ ì˜ìƒ ìˆ˜ì‹  (ê¶Œì¥, ë¹ ë¦„). web_server ì—†ì´ ì‚¬ìš© ê°€ëŠ¥",
    )
    parser.add_argument("--add-person", "-a", type=str, help="ìƒˆë¡œìš´ ì‚¬ëŒ í´ë˜ìŠ¤ ì¶”ê°€")

    args = parser.parse_args()

    # ìƒˆë¡œìš´ ì‚¬ëŒ ì¶”ê°€
    if args.add_person:
        add_new_person(args.add_person)
        return

    # ìº¡ì²˜ ë° ë¼ë²¨ë§ ì‹œì‘
    capture_and_label(
        stream_url=args.stream,
        model_path=args.model,
        target_class_id=args.class_id,
        save_interval=args.interval,
        confidence_threshold=args.confidence,
        skip_frames=args.skip_frames,
        use_ros2=args.ros2,
    )


if __name__ == "__main__":
    main()
